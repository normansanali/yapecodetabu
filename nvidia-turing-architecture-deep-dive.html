<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Turing RT Cores: Hybrid Rendering and Real Time Raytracing -</title><meta name=robots content="index,follow,noarchive"><meta name=description content="As it presents itself in Turing, real-time raytracing doesn’t completely replace traditional rasterization-based rendering, instead existing as part of Turing’s ‘hybrid rendering’ model. In other words, rasterization is used for most rendering, while ray-tracing techniques are used for select graphical effects. Meanwhile, the ‘real-time’ performance is generally achieved with a very small amount of rays (e.g. 1 or 2) per pixel, and a very large amount of denoising.
The specific implementation is ultimately in the hands of developers, and NVIDIA naturally has their raytracing development ecosystem, which we’ll go over in a later section."><meta name=author content="Jenniffer Sheldon"><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/app.css><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/an-old-hope.min.css><script defer src=https://assets.cdnweb.info/hugo/paper/js/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=./theme.png><link rel=icon href=./favicon.ico><link rel=apple-touch-icon href=./apple-touch-icon.png><meta name=generator content="Hugo 0.98.0"><meta property="og:title" content="Turing RT Cores: Hybrid Rendering and Real Time Raytracing"><meta property="og:description" content="As it presents itself in Turing, real-time raytracing doesnt completely replace traditional rasterization-based rendering, instead existing as part of Turings hybrid rendering model. In other words, rasterization is used for most rendering, while ray-tracing techniques are used for select graphical effects. Meanwhile, the real-time performance is generally achieved with a very small amount of rays"><meta property="og:type" content="article"><meta property="og:url" content="/nvidia-turing-architecture-deep-dive.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-09-22T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-22T00:00:00+00:00"><meta itemprop=name content="Turing RT Cores: Hybrid Rendering and Real Time Raytracing"><meta itemprop=description content="As it presents itself in Turing, real-time raytracing doesnt completely replace traditional rasterization-based rendering, instead existing as part of Turings hybrid rendering model. In other words, rasterization is used for most rendering, while ray-tracing techniques are used for select graphical effects. Meanwhile, the real-time performance is generally achieved with a very small amount of rays"><meta itemprop=datePublished content="2024-09-22T00:00:00+00:00"><meta itemprop=dateModified content="2024-09-22T00:00:00+00:00"><meta itemprop=wordCount content="1063"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Turing RT Cores: Hybrid Rendering and Real Time Raytracing"><meta name=twitter:description content="As it presents itself in Turing, real-time raytracing doesnt completely replace traditional rasterization-based rendering, instead existing as part of Turings hybrid rendering model. In other words, rasterization is used for most rendering, while ray-tracing techniques are used for select graphical effects. Meanwhile, the real-time performance is generally achieved with a very small amount of rays"></head><body class=not-ready data-menu=true><header class=header><p class=logo><a class=site-name href=./index.html>PulseBlog</a><a class=btn-dark></a></p><script>let bodyClx=document.body.classList,btnDark=document.querySelector(".btn-dark"),sysDark=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark"),setDark=e=>{bodyClx[e?"add":"remove"]("dark"),localStorage.setItem("dark",e?"yes":"no")};setDark(darkVal?darkVal==="yes":sysDark.matches),requestAnimationFrame(()=>bodyClx.remove("not-ready")),btnDark.addEventListener("click",()=>setDark(!bodyClx.contains("dark"))),sysDark.addEventListener("change",e=>setDark(e.matches))</script><nav class=menu><a href=./sitemap.xml>Sitemap</a></nav></header><main class=main><article class=post-single><header class=post-title><p><time>Sep 22, 2024</time>
<span>Jenniffer Sheldon</span></p><h1>Turing RT Cores: Hybrid Rendering and Real Time Raytracing</h1></header><section class=post-content><p>As it presents itself in Turing, real-time raytracing doesn’t completely replace traditional rasterization-based rendering, instead existing as part of Turing’s ‘hybrid rendering’ model. In other words, rasterization is used for most rendering, while ray-tracing techniques are used for select graphical effects. Meanwhile, the ‘real-time’ performance is generally achieved with a very small amount of rays (e.g. 1 or 2) per pixel, and a very large amount of denoising.</p><p>The specific implementation is ultimately in the hands of developers, and NVIDIA naturally has their raytracing development ecosystem, which we’ll go over in a later section. But because of the computational intensity, it simply isn’t possible to use real-time raytracing for the complete rendering workload. And higher resolutions, more complex scenes, and numerous graphical effects also compound the difficulty. So for performance reasons, developers will be utilizing raytracing in a deliberate and targeted manner for specific effects, such as global illumination, ambient occlusion, realistic shadows, reflections, and refractions. Likewise, raytracing may be limited to specific objects in a scene, and rasterization and z-buffering may replace primary ray casting while only secondary rays are raytraced. Thus, the goal of developers is to use raytracing for the most noticeable and realistic effects that rasterization cannot accomplish.</p><p>Essentially, this style of ‘hybrid rendering’ is a lot less raytracing than one might imagine from the marketing material. Perhaps a blunt way to generalize might be: real time raytracing in Turing typically means only certain objects are being rendered with certain raytraced graphical effects, using a minimal amount of rays per pixel and/or only raytracing secondary rays, and using a lot of denoising filtering; anything more would affect performance too much. Interestingly, explaining all the caveats this way both undersells and oversells the technology, because therein lies the paradox. Even in this very circumscribed way, GPU performance is significantly affected, but image quality is enhanced with a realism that cannot be provided by a higher resolution or better anti-aliasing. Except ‘real time’ interactivity in gaming essentially means a minimum of 30 to 45 fps, and lowering the render resolution to achieve those framerates hurts image quality. What complicates this is that real time raytracing is indeed considered the ‘holy grail’ of computer graphics, and so managing the feat at all is a big deal, but there are equally valid professional and consumer perspectives on how that translates into a compelling product.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/13282/GeForce_EditorsDay_Aug2018_Updated090318_1536034900-compressed-029_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>On that note, then, NVIDIA accomplished what the industry was not expecting to be possible for at least a few more years, and certainly not at this scale and development ecosystem. Real time raytracing is the culmination of a decade or so of work, and the Turing RT Cores are the lynchpin. But in building up to it, NVIDIA summarizes the achievement as a result of:</p><ul><li>Hybrid rendering pipeline</li><li>Efficient denoising algorithms</li><li>Efficient BVH algorithms</li></ul><p>By themselves, these developments were unable to improve raytracing efficiency, but set the stage for RT Cores. By virtue of raytracing’s importance in the world of computer graphics, NVIDIA Research has been looking into <a href=#>various</a> BVH <a href=#>implementations</a> for quite some time, as well as <a href=#>exploring architectural concerns for raytracing acceleration</a>, something easily noted from their patents and publications. Likewise with denoising, though the latest trend has veered towards using AI and by extension Tensor Cores. When BVH became a standard of sorts, NVIDIA was able to design a corresponding fixed function hardware accelerator.</p><p>Being so crucial to their achievement, NVIDIA is not disclosing many details about the RT Cores or their BVH implementation. Of the details given, much is somewhat generic. To reiterate, BVH is a rather general category, and all modern raytracing acceleration structures are typically BVH or kd-tree based.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/13282/GeForce_EditorsDay_Aug2018_Updated090318_1536034900-compressed-030_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Unlike Tensor Cores, which are better seen as an FMA array alongside the FP and INT cores, the RT Cores are more like a classic offloading IP block. Treated very similar to texture units by the sub-cores, instructions bound for RT Cores are routed out of sub-cores, which is later notified on completion. Upon receiving a ray probe from the SM, the RT Core proceeds to autonomously traverse the BVH and perform ray-intersection tests. This type of <a href=#>‘traversal and intersection’</a> fixed function raytracing accelerator is a well-known concept and has had quite a few implementations over the years, as traversal and intersection testing are two of the most computationally intensive tasks involved. In comparison, traversing the BVH in shaders would require thousands of instruction slots per ray cast, all for testing against bounding box intersections in the BVH.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/13282/GeForce_EditorsDay_Aug2018_Updated090318_1536034900-compressed-031_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Returning to the RT Core, it will then return any hits and letting shaders do implement the result. The RT Core also handles some grouping and scheduling of memory operations for maximizing memory throughput across multiple rays. And given the workload, presumably some amount of memory and/or ray buffer within the SIP block as well. Like in many other workloads, memory bandwidth is a common bottleneck in raytracing, and has been the <a href=#>focus</a> of <a href=#>several</a> NVIDIA Research <a href=#>papers</a>. And in general, raytracing workloads result in <a href=#>very irregular and random memory accesses</a>, mainly due to incoherent rays, that prove especially problematic for how GPUs typically utilize their memory.</p><p>But otherwise, everything else is at a high level governed by the API (i.e. DXR) and the application; construction and update of the BVH is done on CUDA cores, governed by the particular IHV – in this case, NVIDIA – in their DXR implementation.</p><p>All-in-all, there’s clearly more involved, and we’ll be looking to run some microbenchmarks in the future. NVIDIA’s custom BVH algorithms are clearly in play, but right now we can’t say what the optimizations might be, such as compressions, wide BVH, node subdivision into treelets. The way the RT Cores are integrated into the SM and into the architecture is likely crucial to how it operates well. Internally, the RT Core might just be a basic traversal and intersection unit, but it might also have other bits inside; <a href=#>one of NVIDIA’s recent patents</a> provide a representation, albeit dated, of what else might be present. I, for one, would not be surprised to see it closely tied with the MIO blocks, and perhaps did more with coherency gathering by <a href=#>manipulating memory traffic for higher efficiency</a>. It would need to coordinate well with the other workloads in the SMs without strangling memory access with unmitigated incoherent rays.</p><p>Nevertheless, details like performance impact are as yet unspecified.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH50fpdrZqeumZm2onnTrqmippdirrOvx6Krnpukqr%2BmecOenKlllJ7DpnuU</p></section><nav class=post-nav><a class=prev href=./robin-wrights-superfit-body-never-ages-pics.html><span>←</span><span>Robin Wright's Superfit Body Never Ages: Pics</span></a>
<a class=next href=./scott-weilands-quest-for-front-man-reinvention-html.html><span>Where You Going With That Mask I Found? Celebrating Scott Weilands Quest for Front-man Reinventio</span><span>→</span></a></nav></article></main><footer class=footer><p>&copy; 2024 <a href=./></a></p><p>Powered by <a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>️</p></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>